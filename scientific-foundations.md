# Scientific Foundations & Validation

The Axiom Cortex™ engine is built on a foundation of peer-reviewed research in computational linguistics, psychometrics, and artificial intelligence. Our approach is not a black box; it is an auditable, multi-layered system designed for unparalleled accuracy and fairness.

This document provides a high-level overview of the key scientific domains that underpin our methodology.

---

### 1. L2-Aware Mathematical Validation Layer

This is our primary defense against the linguistic and cultural biases that plague standard NLP models. It is a suite of post-hoc integration models that ensure we are measuring a candidate's intellect, not their English proficiency.

*   **Core Principle:** To mathematically separate the *signal* (the quality of the thinking) from the *noise* (the linguistic delivery).
*   **Key Techniques:**
    *   **Proficiency-Normalized Scoring:** We decompose communication scores into semantic content vs. grammatical form errors, removing variance due to L2 proficiency.
    *   **Cross-Lingual Semantic Fidelity:** We use multilingual embeddings and **Fréchet Semantic Distance (FSD)** to prevent any "translation penalty."
    *   **Optimal Transport with Code-Switch Awareness:** We use **2-Wasserstein distance** with a neutral cost mask to avoid penalizing common linguistic code-switches.
    *   **Differential Item Functioning (DIF) Analysis:** We run statistical tests to ensure our evaluation rubrics do not function differently for ESL vs. L1 candidates of the same skill level.

---

### 2. Advanced Measurement & Alignment Models

We employ a suite of modern, data-driven techniques to move beyond simple scoring and into predictive alignment.

*   **Core Principle:** To model the complex, non-linear relationships between interview evidence and on-the-job success.
*   **Key Techniques:**
    *   **Nonparametric Latent Measurement:** We use **isotonic regression and monotone neural networks** to model the relationship between evidence and latent traits, avoiding the rigid assumptions of older models.
    *   **Network Psychometrics (Skill Graphs):** We use **Gaussian Graphical Models (GGMs)** to construct a "skill graph" for each candidate, analyzing the interconnectedness of their skills.
    *   **Dynamic Interviewing via Information Gain:** For active evaluations, the engine can suggest the next question by calculating which one will provide the maximum **Information Gain (ΔH)** about a candidate's core traits.

---

### 3. Reliability, Monitoring, and Decision Theory

A scientific instrument is only as good as its reliability and its decision-making framework.

*   **Core Principle:** To ensure our results are consistent, our models are stable, and our final recommendations are optimal.
*   **Key Techniques:**
    *   **Generalizability Theory:** We use **G-coefficients** to quantify the reliability and consistency of our scoring rubrics.
    *   **Random Matrix Theory:** We analyze the eigen-spectrum of our data against the **Marchenko–Pastur distribution** to detect and eliminate spurious, non-signal factors.
    *   **Constrained Bayesian Decision Theory:** Our final recommendation is not a simple score threshold. It is the output of a constrained optimization process that **maximizes expected utility** while adhering to strict fairness and performance gate constraints.

---

This multi-layered scientific framework is what allows the **Nearshore IT Co-Pilot™** to function as a true **Intelligent Services Infrastructure**. It is the engine that replaces guesswork with auditable, data-driven, and scientifically-validated results.
